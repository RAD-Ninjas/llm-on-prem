# LLM-On-Prem
<p align="center">
  <img src="https://pbs.twimg.com/profile_images/1599457885842448384/w04XUGId_400x400.jpg" alt="Pangea" width="60"/>
  <img src="https://pbs.twimg.com/profile_images/1641380096778055681/xRrCcdkf_400x400.jpg" alt="asdf" width="60"/>
</p>

---

## Introduction

The frontend is a boilerplate app generated by ```npx create-secure-chatgpt-app```. It leverages several of Pangea's security services for securing ChatGPT usage.


## Features

- Frontend:
  - Authentication using Pangea AuthN service and NextJS framework
  - Secure `chat` page
  - Secure `chat/generate` api endpoint
  - Redacting user prompts using Pangea's Redact service
  - Auditing user prompts using Pangea's Secure Audit Log service
  - De-fanging malicious responses from OpenAI API using Pangea's Domain Intel and URL Intel services

- Backend:
  - lm-sys [FastChat server](https://github.com/lm-sys/FastChat/blob/main/docs/openai_api.md) configured to operate as a stand-in for the OpenAI API
  - VLLM inference engine worker
  - Supports multiple HF transformer models
